{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e44a789",
   "metadata": {},
   "source": [
    "# Google Play Store Data Analysis (EDA using Python)\n",
    "\n",
    "**Project:** Exploratory Data Analysis of Google Play Store apps dataset using Python, Pandas, NumPy, and Matplotlib.\n",
    "\n",
    "Place the dataset file `googleplaystore.csv` in the same folder as this notebook before running. The notebook is structured and commented so recruiters or interviewers can follow your process.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccb4009",
   "metadata": {},
   "source": [
    "## 1. Libraries & Settings\n",
    "Import required libraries and basic settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4a46ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Matplotlib default settings (do not set custom colors unless requested)\n",
    "plt.rcParams['figure.figsize'] = (10,6)\n",
    "plt.rcParams['axes.grid'] = True\n",
    "\n",
    "print('Libraries imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea2e0c0",
   "metadata": {},
   "source": [
    "## 2. Load dataset\n",
    "The notebook expects a `googleplaystore.csv` file. If you have a differently named file, change the path below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da47cd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'googleplaystore.csv'\n",
    "\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    print(f\"Dataset not found at {DATA_PATH}. Please upload the CSV into the notebook folder and re-run this cell.\")\n",
    "else:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print('Loaded dataset with shape:', df.shape)\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f772d2",
   "metadata": {},
   "source": [
    "## 3. Initial inspection\n",
    "Check columns, dtypes, missing values and quick stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4528b217",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in globals():\n",
    "    display(df.info())\n",
    "    display(df.describe(include='all').T)\n",
    "    missing = df.isnull().sum().sort_values(ascending=False)\n",
    "    display(missing[missing>0])\n",
    "else:\n",
    "    print('Load the dataset first.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24efef53",
   "metadata": {},
   "source": [
    "## 4. Data cleaning & transformation\n",
    "Common cleaning steps used in the project. Each step is reversible via copying the original dataset or by re-running the cell sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8de073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_googleplay(df):\n",
    "    df = df.copy()\n",
    "    # Standard column name cleanup\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "    # Remove duplicates based on 'App' column if exists\n",
    "    if 'App' in df.columns:\n",
    "        before = df.shape[0]\n",
    "        df = df.drop_duplicates(subset=['App'], keep='first')\n",
    "        after = df.shape[0]\n",
    "        print(f'Removed {before-after} duplicate rows based on App column')\n",
    "\n",
    "    # Clean 'Installs' column -> numeric\n",
    "    if 'Installs' in df.columns:\n",
    "        df['Installs'] = df['Installs'].astype(str).str.replace('[+,]', '', regex=True).str.replace('Free', '')\n",
    "        df['Installs'] = pd.to_numeric(df['Installs'], errors='coerce')\n",
    "\n",
    "    # Clean 'Price' column -> numeric\n",
    "    if 'Price' in df.columns:\n",
    "        df['Price'] = df['Price'].astype(str).str.replace('[$,]', '', regex=True)\n",
    "        df['Price'] = pd.to_numeric(df['Price'], errors='coerce')\n",
    "\n",
    "    # Convert 'Reviews' to numeric\n",
    "    if 'Reviews' in df.columns:\n",
    "        df['Reviews'] = pd.to_numeric(df['Reviews'], errors='coerce')\n",
    "\n",
    "    # Clean 'Size' column: handle 'M', 'k' and 'Varies with device'\n",
    "    if 'Size' in df.columns:\n",
    "        def parse_size(x):\n",
    "            x = str(x).strip()\n",
    "            if x in ['Varies with device', 'nan', 'None']:\n",
    "                return np.nan\n",
    "            if x.endswith('M'):\n",
    "                try:\n",
    "                    return float(x[:-1]) * 1e6\n",
    "                except:\n",
    "                    return np.nan\n",
    "            if x.endswith('k'):\n",
    "                try:\n",
    "                    return float(x[:-1]) * 1e3\n",
    "                except:\n",
    "                    return np.nan\n",
    "            try:\n",
    "                return float(x)\n",
    "            except:\n",
    "                return np.nan\n",
    "        df['Size_bytes'] = df['Size'].apply(parse_size)\n",
    "\n",
    "    # Ratings to numeric\n",
    "    if 'Rating' in df.columns:\n",
    "        df['Rating'] = pd.to_numeric(df['Rating'], errors='coerce')\n",
    "\n",
    "    # Last Updated -> datetime\n",
    "    if 'Last Updated' in df.columns:\n",
    "        df['Last Updated'] = pd.to_datetime(df['Last Updated'], errors='coerce')\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply cleaning if dataset loaded\n",
    "if 'df' in globals():\n",
    "    df_clean = clean_googleplay(df)\n",
    "    print('Cleaning complete. Clean shape:', df_clean.shape)\n",
    "    display(df_clean.head())\n",
    "else:\n",
    "    print('Load the dataset first.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f1ec18",
   "metadata": {},
   "source": [
    "### 4.1 Handling missing values\n",
    "Examples: drop rows with no App name, impute Rating with median, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962d37b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_clean' in globals():\n",
    "    df2 = df_clean.copy()\n",
    "    # Drop rows with missing App names\n",
    "    if 'App' in df2.columns:\n",
    "        df2 = df2[~df2['App'].isnull()]\n",
    "\n",
    "    # Impute Rating with median\n",
    "    if 'Rating' in df2.columns:\n",
    "        median_rating = df2['Rating'].median()\n",
    "        df2['Rating_imputed'] = df2['Rating'].fillna(median_rating)\n",
    "        print('Imputed Rating nulls with median:', median_rating)\n",
    "\n",
    "    # Fill installs nulls with 0 (or keep as NaN based on your preference)\n",
    "    if 'Installs' in df2.columns:\n",
    "        df2['Installs'] = df2['Installs'].fillna(0)\n",
    "\n",
    "    display(df2.isnull().sum().sort_values(ascending=False).head(10))\n",
    "else:\n",
    "    print('Run cleaning first.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a87e63e",
   "metadata": {},
   "source": [
    "## 5. Feature engineering\n",
    "Create useful features like 'is_free', 'category_encoded', 'days_since_update', 'log_installs'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c04e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df2' in globals():\n",
    "    df3 = df2.copy()\n",
    "    if 'Type' in df3.columns:\n",
    "        df3['is_free'] = df3['Type'].str.lower().eq('free')\n",
    "    else:\n",
    "        # Some datasets have Price column only\n",
    "        if 'Price' in df3.columns:\n",
    "            df3['is_free'] = df3['Price'].fillna(0) == 0\n",
    "\n",
    "    if 'Installs' in df3.columns:\n",
    "        # Add log installs to reduce skew\n",
    "        df3['log_installs'] = df3['Installs'].apply(lambda x: np.log1p(x))\n",
    "\n",
    "    if 'Category' in df3.columns:\n",
    "        df3['Category'] = df3['Category'].astype(str)\n",
    "        df3['Category_code'] = df3['Category'].astype('category').cat.codes\n",
    "\n",
    "    if 'Last Updated' in df3.columns:\n",
    "        df3['days_since_update'] = (pd.Timestamp.today() - df3['Last Updated']).dt.days\n",
    "\n",
    "    display(df3.head())\n",
    "else:\n",
    "    print('Run previous steps first.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02d0cb5",
   "metadata": {},
   "source": [
    "## 6. Exploratory Data Analysis (EDA)\n",
    "Several visualizations: distributions, bar plots, scatter plots and boxplots.\n",
    "Each plot uses matplotlib only and is independent (no seaborn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673a4682",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df3' in globals():\n",
    "    # Rating distribution\n",
    "    if 'Rating_imputed' in df3.columns:\n",
    "        plt.figure()\n",
    "        plt.hist(df3['Rating_imputed'].dropna(), bins=20)\n",
    "        plt.title('Distribution of App Ratings (imputed)')\n",
    "        plt.xlabel('Rating')\n",
    "        plt.ylabel('Count')\n",
    "        plt.show()\n",
    "\n",
    "    # Top categories by number of apps\n",
    "    if 'Category' in df3.columns:\n",
    "        top_cats = df3['Category'].value_counts().nlargest(10)\n",
    "        plt.figure()\n",
    "        top_cats.plot.bar()\n",
    "        plt.title('Top 10 App Categories by Count')\n",
    "        plt.xlabel('Category')\n",
    "        plt.ylabel('Number of Apps')\n",
    "        plt.show()\n",
    "\n",
    "    # Installs vs Rating scatter\n",
    "    if 'Installs' in df3.columns and 'Rating_imputed' in df3.columns:\n",
    "        plt.figure()\n",
    "        plt.scatter(df3['Installs'], df3['Rating_imputed'], alpha=0.4)\n",
    "        plt.xscale('log')\n",
    "        plt.title('Installs vs Rating')\n",
    "        plt.xlabel('Installs (log scale)')\n",
    "        plt.ylabel('Rating')\n",
    "        plt.show()\n",
    "\n",
    "    # Boxplot: Rating by Type (Free/Paid)\n",
    "    if 'is_free' in df3.columns:\n",
    "        plt.figure()\n",
    "        groups = [df3[df3['is_free']==val]['Rating_imputed'].dropna() for val in [True, False]]\n",
    "        plt.boxplot(groups, labels=['Free','Paid'])\n",
    "        plt.title('Rating distribution: Free vs Paid')\n",
    "        plt.ylabel('Rating')\n",
    "        plt.show()\n",
    "\n",
    "else:\n",
    "    print('Run feature engineering first.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861c2da5",
   "metadata": {},
   "source": [
    "### 6.1 Correlations & Top apps\n",
    "Check numeric correlations and list top-performing apps by installs/reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab79d3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df3' in globals():\n",
    "    numeric = df3.select_dtypes(include=[np.number])\n",
    "    if not numeric.empty:\n",
    "        corr = numeric.corr()\n",
    "        display(corr)\n",
    "\n",
    "    # Top 20 apps by installs\n",
    "    if 'Installs' in df3.columns and 'App' in df3.columns:\n",
    "        top_by_installs = df3.sort_values('Installs', ascending=False).head(20)[['App','Category','Installs','Rating_imputed']]\n",
    "        display(top_by_installs)\n",
    "else:\n",
    "    print('Run previous steps first.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb78838",
   "metadata": {},
   "source": [
    "## 7. Key insights (examples)\n",
    "- Free apps dominate in count.\n",
    "- Certain categories (e.g., GAME, FAMILY) often have higher installs.\n",
    "- Ratings have limited correlation with installs in many cases â€” high installs don't always mean higher rating.\n",
    "\n",
    "> Replace these example insights with your actual findings after running the notebook on your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd2737a",
   "metadata": {},
   "source": [
    "## 8. Next steps / Enhancements\n",
    "- Sentiment analysis on reviews (NLP)\n",
    "- Build predictive models (e.g., predict high-install apps)\n",
    "- Create an interactive dashboard with Plotly Dash or Streamlit\n",
    "- Deploy cleaned dataset and notebook to GitHub with README and images\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Reproducibility\n",
    "Ensure the repository contains:\n",
    "- `googleplaystore.csv`\n",
    "- `google_play_eda.ipynb` (this notebook)\n",
    "- `README.md` with project summary and sample images\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
